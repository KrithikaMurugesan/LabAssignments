{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kritz/anaconda3/envs/scripts/lib/python3.6/site-packages/ipykernel_launcher.py:8: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "import pandas as pd\n",
    "\n",
    "sc = SparkContext()\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "train = pd.read_csv(r'/home/kritz/Documents/DDL/Ex09/tags.dat',sep=\"::\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 95580 entries, 0 to 95579\n",
      "Data columns (total 4 columns):\n",
      "userId       95580 non-null int64\n",
      "movieaId     95580 non-null int64\n",
      "tag          95564 non-null object\n",
      "timestamp    95580 non-null int64\n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train.columns=[\"userId\",\"movieaId\",\"tag\",\"timestamp\"]\n",
    "train.head()\n",
    "train.info()\n",
    "train['tag']= train['tag'].astype(str)\n",
    "data = sqlContext.createDataFrame(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql import types as t\n",
    "data = data.withColumn('time', f.date_format(data.timestamp.cast(dataType=t.TimestampType()), \"dd-MM-yyyy HH:mm:ss\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "data.dtypes\n",
    "data = data.withColumn('new_time',to_timestamp(data.time, 'dd-MM-yyyy HH:mm:ss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+--------------------+-------------------+-------+\n",
      "|userId|movieaId|                 tag|           new_time|session|\n",
      "+------+--------+--------------------+-------------------+-------+\n",
      "|  1806|   43560|              comedy|2006-05-18 22:23:28|      1|\n",
      "|  1806|   43560|                kids|2006-05-18 22:23:28|      1|\n",
      "|  1806|    7018|            language|2007-02-22 16:24:59|      2|\n",
      "|  1806|    7152|              nudity|2007-04-13 19:05:53|      3|\n",
      "|  1806|    7152|                dark|2007-04-13 19:06:30|      3|\n",
      "|  1806|   44709|        heartwarming|2007-04-13 19:26:25|      3|\n",
      "|  1806|   44199|intelligent thriller|2007-04-13 19:28:17|      3|\n",
      "|  1806|   43936|               tense|2007-04-13 19:29:36|      3|\n",
      "|  1806|   43928|              stupid|2007-04-13 19:30:29|      3|\n",
      "|  1806|   42734|              clever|2007-04-13 19:32:16|      3|\n",
      "+------+--------+--------------------+-------------------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Window\n",
    "w = Window.partitionBy(\"userId\").orderBy(asc(\"new_time\"))\n",
    "dataNew = data.withColumn('lag',lag(data.new_time).over(w))\n",
    "timeFmt = \"yyyy-MM-dd'T'HH:mm:ss\"\n",
    "dataNew = dataNew.withColumn('diff',when((unix_timestamp(dataNew.new_time, format=timeFmt)\n",
    "            - unix_timestamp(dataNew.lag, format=timeFmt))/60 < 30,0).otherwise(1))\n",
    "dataNew = dataNew.withColumn('session', sum('diff').over(w))\n",
    "columns_to_drop = ['time', 'lag','timestamp','diff']\n",
    "dataNew = dataNew.drop(*columns_to_drop)\n",
    "dataNew.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+\n",
      "|userId|max(session)|\n",
      "+------+------------+\n",
      "| 10555|         891|\n",
      "| 23172|         482|\n",
      "|   146|         333|\n",
      "| 33384|         269|\n",
      "| 47448|         199|\n",
      "| 34745|         144|\n",
      "| 11898|         127|\n",
      "| 30167|         115|\n",
      "| 64633|         108|\n",
      "|  8041|         104|\n",
      "+------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "frequency = dataNew.groupBy(\"userId\").max(\"session\").orderBy('max(session)', ascending=False)\n",
    "frequency.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|userId|      avg(session)|\n",
      "+------+------------------+\n",
      "| 10555| 530.8542914171657|\n",
      "| 23172|267.95190877540904|\n",
      "|   146| 128.9478155339806|\n",
      "| 33384|109.33039647577093|\n",
      "| 47448| 91.14512195121951|\n",
      "| 11898| 62.71298174442191|\n",
      "| 64633| 56.24504249291785|\n",
      "| 34745| 53.15585443037975|\n",
      "| 41838|43.367198838896954|\n",
      "|  6362|          43.28125|\n",
      "| 23388| 38.94854586129754|\n",
      "| 50970| 34.81666666666667|\n",
      "|  8041| 34.44179104477612|\n",
      "| 32828|29.953929539295395|\n",
      "|  3962|29.456043956043956|\n",
      "| 19460|29.116071428571427|\n",
      "| 48621| 29.08076923076923|\n",
      "| 49882| 28.65049928673324|\n",
      "| 24221|  27.5472972972973|\n",
      "| 39689| 27.19685039370079|\n",
      "+------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataNew.groupBy(\"userId\").mean(\"session\").orderBy('avg(session)', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|userId|stddev_samp(session)|\n",
      "+------+--------------------+\n",
      "|  1806|  1.2004900959975617|\n",
      "|  2040|                 0.0|\n",
      "| 15437|                 NaN|\n",
      "| 15663|                 NaN|\n",
      "| 15846|                 0.0|\n",
      "| 18295|                 0.5|\n",
      "| 18730|                 NaN|\n",
      "| 19141|                 NaN|\n",
      "| 25649|  1.2909944487358056|\n",
      "| 27919|  0.5773502691896258|\n",
      "| 29018|                 NaN|\n",
      "| 31156|                 NaN|\n",
      "| 37098|                 NaN|\n",
      "| 39104|                 NaN|\n",
      "| 39713|  0.5773502691896258|\n",
      "| 48280|  0.5773502691896257|\n",
      "| 50049|                 0.0|\n",
      "| 55700|                 NaN|\n",
      "| 60016|                 NaN|\n",
      "| 60738|                 0.0|\n",
      "+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataNew.groupBy(\"userId\").agg(stddev(\"session\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = dataNew.agg(mean(\"session\")).collect()[0]['avg(session)']\n",
    "std = dataNew.agg(stddev(\"session\")).collect()[0]['stddev_samp(session)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of session frequency across all users is  61.71259677756853  and std is  150.1792632124109\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean of session frequency across all users is \", avg,\" and std is \",std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "userMean = dataNew.groupBy(\"userId\").mean(\"session\").orderBy('avg(session)', ascending=False)\n",
    "temp = userMean.withColumn(\"checkMean\",when(userMean[\"avg(session)\"] < (2*std), 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|userId|\n",
      "+------+\n",
      "| 62989|\n",
      "|  1806|\n",
      "| 25649|\n",
      "| 18295|\n",
      "| 27919|\n",
      "| 48280|\n",
      "| 39713|\n",
      "|  2040|\n",
      "| 15437|\n",
      "| 15663|\n",
      "| 15846|\n",
      "| 18730|\n",
      "| 19141|\n",
      "| 29018|\n",
      "| 31156|\n",
      "| 37098|\n",
      "| 39104|\n",
      "| 50049|\n",
      "| 55700|\n",
      "| 60016|\n",
      "+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users = temp.filter(temp.checkMean == 1)\n",
    "users.select('userId').distinct().show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
